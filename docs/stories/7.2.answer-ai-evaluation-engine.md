# Story 7.2: Answer Writing - AI Evaluation Engine

**Epic:** 7 - Practice & Evaluation - Answer Writing & Essays
**Story Number:** 7.2
**Status:** Draft
**Created:** December 23, 2025
**Sprint:** Sprint 8 (Epic 7)
**Estimated Effort:** Large (L)
**Risk Level:** HIGH

---

## Story

**As a** UPSC aspirant,
**I want** my answers to be evaluated by AI with rubric-based scoring,
**so that** I receive objective feedback on content, structure, and presentation.

---

## Acceptance Criteria

1. Evaluation rubric: Content (40%), Structure (30%), Language (20%), Examples (10%)
2. Edge Function: `evaluate_answer_pipe.ts` receives answer submission
3. Content scoring: checks for keyword coverage, factual accuracy, depth of analysis using RAG search
4. Structure scoring: analyzes introduction, body paragraphs, conclusion, logical flow
5. Language scoring: grammar check, sentence complexity, word choice, readability
6. Examples scoring: identifies use of case studies, data points, committee reports, Acts/Articles
7. AI prompt: "Evaluate this UPSC Mains answer for question '{question}'. Provide scores for Content, Structure, Language, Examples and detailed feedback."
8. Database: `answer_evaluations` table with submission_id, content_score, structure_score, language_score, examples_score, total_score, feedback_json
9. Scoring scale: 0-10 for each category, total out of 40 (converted to percentage)
10. Processing time: evaluation completes within 30 seconds, shows loading state

---

## Dependencies

**Blocking:** Stories 7.1, 0.3, 1.7 (submission interface, A4F API, RAG search)
**Blocks:** Story 7.3

---

## Definition of Done

- [ ] All AC met
- [ ] Evaluation accurate
- [ ] Rubric scoring working
- [ ] Processing fast enough
- [ ] Tests passing

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-23 | 1.0 | Initial story creation | Bob (SM Agent) |
