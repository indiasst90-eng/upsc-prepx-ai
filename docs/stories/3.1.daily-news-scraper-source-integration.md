# Story 3.1: Daily News Scraper - Source Integration

**Epic:** 3 - Video Generation Pipeline - Daily Current Affairs
**Story Number:** 3.1
**Status:** Draft
**Created:** December 23, 2025
**Sprint:** Sprint 4 (Epic 3)
**Estimated Effort:** Large (L)
**Risk Level:** HIGH (External dependencies)

---

## Story

**As a** system administrator,
**I want** automated daily scraping of whitelisted UPSC news sources with deduplication and relevance filtering,
**so that** current affairs videos contain only high-quality, UPSC-relevant content from trusted sources.

---

## Scope

**INCLUDED:**
- Scheduled Edge Function (5 AM IST daily)
- Scraping 8 whitelisted sources
- DuckDuckGo Search Service integration
- Article extraction and parsing
- LLM relevance classification
- Deduplication via embeddings
- Database storage
- Rate limiting and error handling
- Monitoring and fallback

**NOT INCLUDED:**
- Script generation (Story 3.2)
- Video rendering (Stories 3.3-3.4)
- PDF generation (Story 3.6)
- Manual article submission interface

---

## Acceptance Criteria

1. Edge Function scheduled via pg_cron: daily_news_scraper runs at 5:00 AM IST daily
2. Whitelisted sources scraped: visionias.in, drishtiias.com, thehindu.com, pib.gov.in, forumias.com, insightsonindia.com, iasbaba.com, iasscore.in
3. DuckDuckGo Search Service called: POST http://89.117.60.144:8102/search with domain filters
4. Article extraction: title, summary, body text, published date, source URL, category tags
5. Relevance filtering: LLM classifies each article (UPSC-relevant yes/no, subjects, papers)
6. Deduplication: cosine similarity on embeddings, merge articles >90% similar
7. Articles saved to daily_updates table: status = pending_video
8. Rate limiting: max 5 requests/second per source, exponential backoff on failure
9. Monitoring: log article counts, sources success/failure, runtime (<30 minutes)
10. Fallback: if scraper fails, alert admin, use previous day backup content

---

## Dependencies

**Blocking:** Stories 1.4 (daily_updates table), 0.7 (Search Service)
**Blocks:** Story 3.2 (Script Generator)

---

## Definition of Done

- [ ] All AC met
- [ ] Scraper scheduled and running daily
- [ ] All 8 sources integrated
- [ ] Relevance filtering working
- [ ] Deduplication functional
- [ ] Articles saved to database
- [ ] Monitoring dashboard shows metrics
- [ ] Tested for 7 consecutive days

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-12-23 | 1.0 | Initial story creation | Bob (SM Agent) |
| 2025-12-24 | 1.1 | Added Dev Notes and Tasks/Subtasks | Bob (SM Agent) |

---

## Dev Notes

### Relevant Source Tree Info

**File Locations:**
- Edge Functions: `packages/supabase/functions/cron/daily_news_scraper/`
- Database Tables: `daily_updates`, `daily_updates_sources`
- VPS Service: DuckDuckGo Search at `http://89.117.60.144:8102`

### Data Models

**Database Schema:**
```typescript
interface DailyUpdate {
  id: UUID
  title: TEXT NOT NULL
  summary: TEXT
  body_text: TEXT
  source_url: TEXT NOT NULL
  source_name: TEXT
  published_date: TIMESTAMPTZ
  scraped_at: TIMESTAMPTZ
  category_tags: TEXT[]  -- ['Polity', 'Economy', etc.]
  upsc_relevant: BOOLEAN
  relevance_score: DECIMAL
  subjects: TEXT[]  -- GS1, GS2, etc.
  papers: TEXT[]
  status: TEXT  -- 'pending_video', 'queued_script', 'queued_render', 'published', 'failed'
  embedding: vector(1536)
  created_at: TIMESTAMPTZ
}

interface DailyUpdateSource {
  id: UUID
  source_name: TEXT UNIQUE
  base_url: TEXT
  is_active: BOOLEAN
  last_scraped_at: TIMESTAMPTZ
  articles_count: INTEGER
}
```

### API Specifications

**Cron Job:** `daily_news_scraper`
- Location: `packages/supabase/functions/cron/daily_news_scraper/index.ts`
- Schedule: pg_cron - 5:00 AM IST daily
- Request: None (cron triggered)

**VPS Search Service:**
- URL: `http://89.117.60.144:8102/search`
- Method: POST
- Payload: `{ query: string, domains: string[], num_results: number }`

### Testing Standards

**Test File Location:**
- Unit Tests: `packages/supabase/functions/cron/daily_news_scraper/index.test.ts`
- Test Framework: Deno Test

---

## Tasks / Subtasks

- [ ] **Task 1: Database Schema (AC: 6, 10)**
  - [ ] 1.1 Create migration: `007_daily_updates.sql`
  - [ ] 1.2 Create `daily_updates` and `daily_updates_sources` tables
  - [ ] 1.3 Add indexes on published_date, status, source_name
  - [ ] 1.4 Seed whitelisted sources
  - [ ] 1.5 Update TypeScript types

- [ ] **Task 2: Cron Job Setup (AC: 1)**
  - [ ] 2.1 Create `packages/supabase/functions/cron/daily_news_scraper/index.ts`
  - [ ] 2.2 Schedule via PostgreSQL cron: `SELECT cron.schedule('daily_scraper', '0 5 * * *', ...)`
  - [ ] 2.3 Function runs at 5:00 AM IST daily
  - [ ] 2.4 Log execution start/end times

- [ ] **Task 3: Source Integration (AC: 2, 5)**
  - [ ] 3.1 Create `scrapeSource()` function for each whitelisted source
  - [ ] 3.2 Integrate DuckDuckGo Search Service for web search
  - [ ] 3.3 Extract article metadata: title, summary, body, date, URL
  - [ ] 3.4 Parse HTML content using cheerio or similar
  - [ ] 3.5 Handle different source formats

- [ ] **Task 4: Relevance Classification (AC: 5)**
  - [ ] 4.1 Create `classifyRelevance()` function
  - [ ] 4.2 Call A4F LLM to classify articles as UPSC-relevant
  - [ ] 4.3 Extract: subjects (Polity, History...), papers (GS1-4, CSAT)
  - [ ] 4.4 Assign relevance score (0-1)
  - [ ] 4.5 Set `upsc_relevant = true` if score > 0.7

- [ ] **Task 5: Deduplication (AC: 6)**
  - [ ] 5.1 Generate embeddings for all new articles
  - [ ] 5.2 Create `deduplicateArticles()` function
  - [ ] 5.3 Calculate cosine similarity between embeddings
  - [ ] 5.4 Merge articles with >90% similarity
  - [ ] 5.5 Keep most recent/relevant version

- [ ] **Task 6: Rate Limiting (AC: 8)**
  - [ ] 6.1 Implement rate limiter: max 5 requests/second
  - [ ] 6.2 Track request counts per source
  - [ ] 6.3 Exponential backoff on 429 errors
  - [ ] 6.4 Log rate limit violations

- [ ] **Task 7: Monitoring (AC: 9)**
  - [ ] 7.1 Log article counts per source
  - [ ] 7.2 Log success/failure status per source
  - [ ] 7.3 Measure total runtime (<30 minutes target)
  - [ ] 7.4 Store metrics in monitoring table

- [ ] **Task 8: Fallback System (AC: 10)**
  - [ ] 8.1 Implement backup content retrieval
  - [ ] 8.2 If scraper fails, alert admin
  - [ ] 8.3 Use cached content from previous day
  - [ ] 8.4 Manual trigger option for re-scraping

- [ ] **Task 9: Unit Tests**
  - [ ] 9.1 Deno test: source scraping
  - [ ] 9.2 Deno test: relevance classification
  - [ ] 9.3 Deno test: deduplication
  - [ ] 9.4 Deno test: rate limiting

- [ ] **Task 10: Integration Testing**
  - [ ] 10.1 Test 7-day consecutive run
  - [ ] 10.2 Verify all 8 sources integrated

---

## QA Results

**Validation Date:** December 24, 2025
**Validated By:** Bob (SM Agent) - Story Draft Checklist

| Category                             | Status | Issues |
| ------------------------------------ | ------ | ------ |
| 1. Goal & Context Clarity            | PASS   | None   |
| 2. Technical Implementation Guidance | PASS   | None   |
| 3. Reference Effectiveness           | PASS   | None   |
| 4. Self-Containment Assessment       | PASS   | None   |
| 5. Testing Guidance                  | PASS   | None   |

**Final Assessment:** READY - The story provides sufficient context for implementation

**Story Status:** Draft â†’ **Ready for Review**
